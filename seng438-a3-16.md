**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report #3 – Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group \#:      | 16                        |
| -------------- | ------------------------- |
| Student Names: | Dominic Choi              |
|                | Angelo Jerome T. Reynante |
|                | Nathan Ante               |
|                | Karam Baroud              |

(Note that some labs require individual reports while others require one report
for each group. Please see each lab document for details.)

# 1 Introduction

# 1. Introduction

This lab introduces of understanding Whitebox testing and coverage methods involving control flow and data flow coverage. It also allows us to familiarize ourselves with coverage tools like EclEmma, and coverage metrics, like statement, branch, and method coverage.

Our group is meant to use the Blackbox unit tests written in assignment 2 and apply Whitebox testing and coverage techniques to improve them. 
For Section 3.1, we evaluated our previous unit tests from assignment 2 against three metrics: line, branch, and method coverage. 
For Section 3.2, we manually measured data flow coverage by creating Data Flow Graphs ...
For Section 3.3, we updated our existing unit tests to further improve their coverage against the three chosen metrics.

Our initial knowledge of Whitebox testing came from content covered in lectures. The lectures explained that Whitebox testing focuses on creating tests based on knowledge of the internal structure and code of the system. We can develop Whitebox tests to satisfy coverage criterias. For Control Flow Coverage, metrics to evaluate could be statement, branch, condition, MC/DC, and path coverage. For Data Flow Coverage, metrics to evaluate could be All-Definitions, All-Uses, and All-DU Paths coverage. These coverage criteria can help in the development and improvement of unit tests. By satisfying different coverage criteria and ensuring the execution of different paths in the program, we can reduce bugs in our system.

# 2 Manual data-flow coverage calculations for X and Y methods

Text…

# 3 A detailed description of the testing strategy for the new unit test

Testing Strategy:
- Look at our existing unit tests and improve their statement, branch, and method coverage.

# 4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage

Text…

# 5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)

Text…

# 6 Pros and Cons of coverage tools used and Metrics you report

Text…

# 7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation.

Text…

# 8 A discussion on how the team work/effort was divided and managed

We all collaborated in a Liveshare session while discussing in a voice call.
We also all worked on the report together

# 9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab

Challenges faced for this lab is fixing the test cases. Some test cases may fail due to the fact that we didn't assign the arguments correctly.

# 10 Comments/feedback on the lab itself

Text…
